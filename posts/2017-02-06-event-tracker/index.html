<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Visualizing parallel event series in Python | Dario Arcos-D√≠az, PhD</title><meta name=keywords content="time series,visualization"><meta name=description content="In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data."><meta name=author content="Dario Arcos-D√≠az"><link rel=canonical href=https://www.arcosdiaz.com/blog/posts/2017-02-06-event-tracker/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.da3211e5ef867bf2b75fd5a6515cfed7195c011e8ab735694e203810a827097b.css integrity="sha256-2jIR5e+Ge/K3X9WmUVz+1xlcAR6KtzVpTiA4EKgnCXs=" rel="preload stylesheet" as=style><link rel=icon href=https://www.arcosdiaz.com/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.arcosdiaz.com/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.arcosdiaz.com/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://www.arcosdiaz.com/blog/apple-touch-icon.png><link rel=mask-icon href=https://www.arcosdiaz.com/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://www.arcosdiaz.com/blog/posts/2017-02-06-event-tracker/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-2Q04SCXNNC"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2Q04SCXNNC")}</script><meta property="og:url" content="https://www.arcosdiaz.com/blog/posts/2017-02-06-event-tracker/"><meta property="og:site_name" content="Dario Arcos-D√≠az, PhD"><meta property="og:title" content="Visualizing parallel event series in Python"><meta property="og:description" content="In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-02-06T00:00:00+00:00"><meta property="article:modified_time" content="2017-02-06T00:00:00+00:00"><meta property="article:tag" content="Time Series"><meta property="article:tag" content="Visualization"><meta property="og:image" content="https://www.arcosdiaz.com/images/event-tracker_thumb.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.arcosdiaz.com/images/event-tracker_thumb.png"><meta name=twitter:title content="Visualizing parallel event series in Python"><meta name=twitter:description content="In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.arcosdiaz.com/blog/posts/"},{"@type":"ListItem","position":2,"name":"Visualizing parallel event series in Python","item":"https://www.arcosdiaz.com/blog/posts/2017-02-06-event-tracker/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Visualizing parallel event series in Python","name":"Visualizing parallel event series in Python","description":"In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data.","keywords":["time series","visualization"],"articleBody":"Do movie releases produce literal earthquakes? We always hear about new movie releases being a ‚Äúblast‚Äù, some sure are. But how do two independent events correlate with each other? In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data.\n# Imports from datetime import datetime import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns sns.set_palette('Set2') sns.set_style(\"whitegrid\") %matplotlib inline Getting the data To make this example more fun, I decided to use two independent series of events for which data is readily available in the internet:\nList of earthquakes around the world List of film releases in the USA Clean and prepare earthquake data We start by downloading the .csv export from the world earthquake website to the ‚Äòdata‚Äô directory and reading the file into a pandas DataFrame\ndf = pd.read_csv('data/earthquakes_raw.csv', sep=';') df.dropna((0,1), how='all', inplace=True) df.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } We have to unify the date information from the Date and Year columns. Then we can save the cleaned-up earthquake date data to a file ‚Äòdata/earthquakes.csv‚Äô\ndf['Date'] = df['Date'] + ' ' + df['Year'].map(str) del df['Year'] df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%B %d %Y')) df['Date'].to_csv('data/earthquakes.csv') df.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } Clean and prepare movie release data The movie release data was retrieved from this website and saved to the ‚Äòdata‚Äô directory. We then read the file into a pandas DataFrame. The resulting table tells us the release date and which movies where released on a that date (up to 5 movies).\ndf = pd.read_csv('data/filmrelease_raw.csv', sep=';', header=None) df.dropna((0,1), how='all', inplace=True, thresh=2) df.columns = ['Date', 'Film1', 'Film2', 'Film3', 'Film4', 'Film5'] df.head(), df.tail() ( Date Film1 Film2 \\ 0 Friday, January 9, 2015 Taken 3 NaN 4 Friday, January 16, 2015 Blackhat Paddington 14 Friday, January 23, 2015 Mortdecai Strange Magic 24 Friday, January 30, 2015 Black or White Project Almanac 34 Friday, February 6, 2015 Jupiter Ascending Seventh Son Film3 Film4 Film5 0 NaN NaN NaN 4 The Wedding Ringer NaN NaN 14 The Boy Next Door NaN NaN 24 The Loft NaN NaN 34 SpongeBob Movie: Sponge Out of Water NaN NaN , Date Film1 Film2 \\ 836 Friday, December 9 üé• Office Christmas Party NaN 840 Friday, December 16 üé• Collateral Beauty üé• La La Land 850 Wednesday, December 21 üé• Assassin's Creed üé• Passengers 863 Friday, December 23 üé• Why Him? NaN 867 Sunday, December 25 üé• Fences NaN Film3 Film4 Film5 836 NaN NaN NaN 840 üé• Rogue One: A Star Wars Story NaN NaN 850 üé• Patriots Day üé• Sing NaN 863 NaN NaN NaN 867 NaN NaN NaN ) Talk about raw unclean data! It seems that, at the top of the table, the date information contains the year (2015). However, upon further inspection we can see that the bottom of the table does not show us the year anymore. From the website information we find out that, after the index 716 and onwards, the missing year information is ‚Äò2016‚Äô. So we add this data to the DataFrame and change the date format to a more readable one.\ndf.loc[lambda x: x.index \u003e= 716, 'Date'] += ', 2016' df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%A, %B %d, %Y')) df.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } For the purpose of plotting the frequency of an event, we are not interested in what movies were released, but only in how many on a particular date. We can count the movies by replacing the names with ones and calculating the sum.\n# replace movie names with ones df.iloc[:,1:] = df.iloc[:,1:].replace(r'\\w', 1.0, regex=True) df.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } We can finally get rid of the unnecessary columns and save the clean data to a file. Now we are ready to start plotting our event series data.\ndf['film_sum'] =df[['Film1', 'Film2', 'Film3', 'Film4', 'Film5']].sum(axis=1) df.drop(['Film1', 'Film2', 'Film3', 'Film4', 'Film5'], axis=1, inplace=True) df.to_csv('data/filmrelease.csv') df.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } Load the data to the plotting variables To use this script, we have to load the clean data that we saved in the previuos steps.\n# Load the earthquake data and add a column with ones since there was only one earthquake per row df1 = pd.read_csv('data/earthquakes.csv', header=None) del df1[0] df1.columns = ['Date'] df1['earthquake'] = np.ones(len(df1)) df1.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } # Load the movie data, the second column already shows us the sum of movie releases df2 = pd.read_csv('data/filmrelease.csv', header=0) del df2['Unnamed: 0'] df2.columns = ['Date', 'movie_release'] df2.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } As end result, we want to have a single DataFrame containing the data for both event series. Moreover, we want to have a continuous time series, including those days in which none of the two events took place (no earthquakes, and no movie releases). We do this by using the concatenate and resample functions of pandas.\n# Concatenate both DataFrames into one df = pd.concat([df1, df2], ignore_index=True) df = df.set_index(pd.DatetimeIndex(df.Date)) df = df.sort_index() df = df.resample('1d').sum().fillna(0) # to complete every day df.head(10) .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } Calculating and plotting a moving average We could simply plot each event occurrence as a data point in a time series. However, this will likely yield a graph that is not very informative. Much easier to grasp is a moving average that tells us the average frequency of the events for a defined period of time in the past. We can create columns for these moving averages, which we can then easily plot.\n# Calculate moving average for i in [7*4, 7*4*2]: mvav = i # moving average period, i.e. number of points to average dfi = np.convolve(df['earthquake'], np.ones((mvav,))*7/mvav # factor for obtaining average , mode='full') df['earthquake moving average %sw' % (int(i/7))] = dfi[:-(i-1)] dfj = np.convolve(df['movie_release'], np.ones((mvav,))*7/mvav # factor for obtaining average , mode='full') df['movie_release moving average %sw' % (int(i/7))] = dfj[:-(i-1)] df.head() .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } The shorter the period that we choose for the moving average, the noisier our graphic will get. Let‚Äôs settle with a moving average that reflects the frequency during the past 8 weeks. And voil√†! Now we can see how the frequency of earthquakes and movie releases changed over time.\n# Plot relevant columns from dataframe df.loc[:,['earthquake moving average 8w', 'movie_release moving average 8w']].\\ plot(cmap='Set2', figsize=(12,4))# possible plt.xlim(df.index[0], df.index.max()+10) plt.title('Moving average of events per week') plt.ylabel('Frequency') plt.show() Descriptive analysis of the event occurrence What other insights can we get from this data set? Two very dissimilar series of events, one natural, and one man-made, will surely have very different properties. Let‚Äôs start with a simple question: on which days of the week do both events typically happen?\n#%% DAY OF THE WEEK ANALYSIS # create column for day of the week df['Day'] = df.index.dayofweek df['Day'] = df.Day.astype('category') df.Day.cat.categories = ['Mon','Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'] # create column for type df['Type'] = np.where(df['earthquake']\u003e0, 'earthquake', np.where(df['movie_release']\u003e0,\\ 'movie_release', np.nan)) df['Type'] = df['Type'].astype('category') df['Type'] = df['Type'].cat.remove_categories(['nan']) # show count for each day #df[(df.Event1 == 1)\u0026(df.Day == 'Mon')].Day.count() # plot count data per day of the week plt.figure() plt.title('Event count per day of the week') sns.countplot(data=df, x='Day', hue='Type') sns.despine(left=True) plt.show() We can see that nature does not respect our weekends, as earthquakes seem to be flatly distributed by day of the week.\nThe movie releases, on the other hand, are most frequent on Friday, followed by Wednesday and a few on Sunday (it‚Äôs almost as if movie release days were chosen by someone‚Ä¶ /s). It seems that, if you‚Äôre planning to release a new movie in the US, Friday is the way to go. People are usually happy to start the weekend with a leisurely activity, so that makes sense. As of why Saturdays and Sundays are almost not used as movie release days, even though on this days people are also usually free from work, it would be interesting to find out why. Another intriguing finding is the not high but remarkable number of releases on Wednesdays. Don‚Äôt people work on Thursdays?\nAnalysis of frequency per week The world is a big place (or is it a small world?) and earthquakes occur all the time, even though we might not always find out. On the other hand, I would expect that movie releases occur much more frequently. So let‚Äôs take a look at the data by plotting histograms for both events side by side.\n# joint histograms plt.figure() df['earthquake moving average 8w'].hist(alpha=.9) df['movie_release moving average 8w'].hist(alpha=.9) plt.title('Histogram of event frequency per week') plt.show() # With seaborn sns.distplot(df['earthquake moving average 8w']), \\ sns.distplot(df['movie_release moving average 8w']) (, ) Luckily, movie releases are much more frequent per week as earthquakes. On most weeks, there are between two and three movie releases, compared to 0.5 to 1.5 earthquakes.\nFinal remarks In this post, we gathered information on the occurrence of two events: earthquakes around the world, and movie releases in the US. By plotting their moving averages we could better compare when they occurred and gained some interesting insights about how they compare. All thanks to Python!\n","wordCount":"1595","inLanguage":"en","image":"https://www.arcosdiaz.com/images/event-tracker_thumb.png","datePublished":"2017-02-06T00:00:00Z","dateModified":"2017-02-06T00:00:00Z","author":{"@type":"Person","name":"Dario Arcos-D√≠az"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.arcosdiaz.com/blog/posts/2017-02-06-event-tracker/"},"publisher":{"@type":"Organization","name":"Dario Arcos-D√≠az, PhD","logo":{"@type":"ImageObject","url":"https://www.arcosdiaz.com/blog/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://www.arcosdiaz.com/blog/ accesskey=h title="Dario Arcos-D√≠az, PhD (Alt + H)">Dario Arcos-D√≠az, PhD</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.arcosdiaz.com/blog/about/ title=About><span>About</span></a></li><li><a href=https://www.arcosdiaz.com/blog/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.arcosdiaz.com/blog/>Home</a>&nbsp;¬ª&nbsp;<a href=https://www.arcosdiaz.com/blog/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Visualizing parallel event series in Python</h1><div class=post-description>In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data.</div><div class=post-meta><span title='2017-02-06 00:00:00 +0000 UTC'>February 6, 2017</span>&nbsp;¬∑&nbsp;<span>8 min</span>&nbsp;¬∑&nbsp;<span>Dario Arcos-D√≠az</span></div></header><figure class=entry-cover><img loading=eager src=https://www.arcosdiaz.com/images/event-tracker_thumb.png alt></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#getting-the-data aria-label="Getting the data">Getting the data</a><ul><li><a href=#clean-and-prepare-earthquake-data aria-label="Clean and prepare earthquake data">Clean and prepare earthquake data</a></li><li><a href=#clean-and-prepare-movie-release-data aria-label="Clean and prepare movie release data">Clean and prepare movie release data</a></li><li><a href=#load-the-data-to-the-plotting-variables aria-label="Load the data to the plotting variables">Load the data to the plotting variables</a></li></ul></li><li><a href=#calculating-and-plotting-a-moving-average aria-label="Calculating and plotting a moving average">Calculating and plotting a moving average</a></li><li><a href=#descriptive-analysis-of-the-event-occurrence aria-label="Descriptive analysis of the event occurrence">Descriptive analysis of the event occurrence</a><ul><li><a href=#analysis-of-frequency-per-week aria-label="Analysis of frequency per week">Analysis of frequency per week</a></li></ul></li><li><a href=#final-remarks aria-label="Final remarks">Final remarks</a></li></ul></div></details></div><div class=post-content><p>Do movie releases produce literal earthquakes? We always hear about new movie releases being a &ldquo;blast&rdquo;, some sure are. But how do two independent events correlate with each other? In this post, I will use Python to visualize two different series of events, plotting them on top of each other to gain insights from time series data.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Imports</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>set_palette(<span style=color:#e6db74>&#39;Set2&#39;</span>)
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>set_style(<span style=color:#e6db74>&#34;whitegrid&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>matplotlib inline
</span></span></code></pre></div><h1 id=getting-the-data>Getting the data<a hidden class=anchor aria-hidden=true href=#getting-the-data>#</a></h1><p>To make this example more fun, I decided to use two independent series of events for which data is readily available in the internet:</p><ul><li><a href="http://world-earthquakes.com/index.php?option=eqs&amp;year=2016">List of earthquakes around the world</a></li><li><a href=http://www.firstshowing.net/schedule2016/>List of film releases in the USA</a></li></ul><h2 id=clean-and-prepare-earthquake-data>Clean and prepare earthquake data<a hidden class=anchor aria-hidden=true href=#clean-and-prepare-earthquake-data>#</a></h2><p>We start by downloading the .csv export from the <a href="http://world-earthquakes.com/index.php?option=eqs&amp;year=2016">world earthquake website</a> to the &lsquo;data&rsquo; directory and reading the file into a pandas DataFrame</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;data/earthquakes_raw.csv&#39;</span>, sep<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;;&#39;</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>dropna((<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>), how<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;all&#39;</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><p>We have to unify the date information from the Date and Year columns. Then we can save the cleaned-up earthquake date data to a file &lsquo;data/earthquakes.csv&rsquo;</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Date&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;Date&#39;</span>] <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39; &#39;</span> <span style=color:#f92672>+</span> df[<span style=color:#e6db74>&#39;Year&#39;</span>]<span style=color:#f92672>.</span>map(str)
</span></span><span style=display:flex><span><span style=color:#66d9ef>del</span> df[<span style=color:#e6db74>&#39;Year&#39;</span>]
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Date&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;Date&#39;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: 
</span></span><span style=display:flex><span>                              datetime<span style=color:#f92672>.</span>strptime(x, <span style=color:#e6db74>&#39;%B </span><span style=color:#e6db74>%d</span><span style=color:#e6db74> %Y&#39;</span>))
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Date&#39;</span>]<span style=color:#f92672>.</span>to_csv(<span style=color:#e6db74>&#39;data/earthquakes.csv&#39;</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><h2 id=clean-and-prepare-movie-release-data>Clean and prepare movie release data<a hidden class=anchor aria-hidden=true href=#clean-and-prepare-movie-release-data>#</a></h2><p>The movie release data was retrieved from <a href=http://www.firstshowing.net/schedule2016/>this website</a> and saved to the &lsquo;data&rsquo; directory. We then read the file into a pandas DataFrame. The resulting table tells us the release date and which movies where released on a that date (up to 5 movies).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;data/filmrelease_raw.csv&#39;</span>, sep<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;;&#39;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>dropna((<span style=color:#ae81ff>0</span>,<span style=color:#ae81ff>1</span>), how<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;all&#39;</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, thresh<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Date&#39;</span>, <span style=color:#e6db74>&#39;Film1&#39;</span>, <span style=color:#e6db74>&#39;Film2&#39;</span>, <span style=color:#e6db74>&#39;Film3&#39;</span>, <span style=color:#e6db74>&#39;Film4&#39;</span>, <span style=color:#e6db74>&#39;Film5&#39;</span>]
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head(), df<span style=color:#f92672>.</span>tail()
</span></span></code></pre></div><pre><code>(                        Date              Film1            Film2  \
 0    Friday, January 9, 2015            Taken 3              NaN   
 4   Friday, January 16, 2015           Blackhat       Paddington   
 14  Friday, January 23, 2015          Mortdecai    Strange Magic   
 24  Friday, January 30, 2015     Black or White  Project Almanac   
 34  Friday, February 6, 2015  Jupiter Ascending      Seventh Son   
 
                                    Film3 Film4 Film5  
 0                                    NaN   NaN   NaN  
 4                     The Wedding Ringer   NaN   NaN  
 14                     The Boy Next Door   NaN   NaN  
 24                              The Loft   NaN   NaN  
 34  SpongeBob Movie: Sponge Out of Water   NaN   NaN  ,
                        Date                     Film1         Film2  \
 836      Friday, December 9  üé• Office Christmas Party           NaN   
 840     Friday, December 16       üé• Collateral Beauty  üé• La La Land   
 850  Wednesday, December 21        üé• Assassin's Creed  üé• Passengers   
 863     Friday, December 23                üé• Why Him?           NaN   
 867     Sunday, December 25                  üé• Fences           NaN   
 
                               Film3   Film4 Film5  
 836                             NaN     NaN   NaN  
 840  üé• Rogue One: A Star Wars Story     NaN   NaN  
 850                  üé• Patriots Day  üé• Sing   NaN  
 863                             NaN     NaN   NaN  
 867                             NaN     NaN   NaN  )
</code></pre><p>Talk about raw <em>unclean</em> data! It seems that, at the top of the table, the date information contains the year (2015). However, upon further inspection we can see that the bottom of the table does not show us the year anymore. From the website information we find out that, after the index 716 and onwards, the missing year information is &lsquo;2016&rsquo;. So we add this data to the DataFrame and change the date format to a more readable one.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span>df<span style=color:#f92672>.</span>loc[<span style=color:#66d9ef>lambda</span> x: x<span style=color:#f92672>.</span>index <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>716</span>, <span style=color:#e6db74>&#39;Date&#39;</span>] <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#39;, 2016&#39;</span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Date&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;Date&#39;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: 
</span></span><span style=display:flex><span>                              datetime<span style=color:#f92672>.</span>strptime(x, <span style=color:#e6db74>&#39;%A, %B </span><span style=color:#e6db74>%d</span><span style=color:#e6db74>, %Y&#39;</span>))
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><p>For the purpose of plotting the frequency of an event, we are not interested in what movies were released, but only in how many on a particular date. We can count the movies by replacing the names with ones and calculating the sum.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># replace movie names with ones</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>iloc[:,<span style=color:#ae81ff>1</span>:] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>iloc[:,<span style=color:#ae81ff>1</span>:]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;\w&#39;</span>, <span style=color:#ae81ff>1.0</span>, regex<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><p>We can finally get rid of the unnecessary columns and save the clean data to a file. Now we are ready to start plotting our event series data.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span>df[<span style=color:#e6db74>&#39;film_sum&#39;</span>] <span style=color:#f92672>=</span>df[[<span style=color:#e6db74>&#39;Film1&#39;</span>, <span style=color:#e6db74>&#39;Film2&#39;</span>, <span style=color:#e6db74>&#39;Film3&#39;</span>, <span style=color:#e6db74>&#39;Film4&#39;</span>, <span style=color:#e6db74>&#39;Film5&#39;</span>]]<span style=color:#f92672>.</span>sum(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>drop([<span style=color:#e6db74>&#39;Film1&#39;</span>, <span style=color:#e6db74>&#39;Film2&#39;</span>, <span style=color:#e6db74>&#39;Film3&#39;</span>, <span style=color:#e6db74>&#39;Film4&#39;</span>, <span style=color:#e6db74>&#39;Film5&#39;</span>], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>to_csv(<span style=color:#e6db74>&#39;data/filmrelease.csv&#39;</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><h2 id=load-the-data-to-the-plotting-variables>Load the data to the plotting variables<a hidden class=anchor aria-hidden=true href=#load-the-data-to-the-plotting-variables>#</a></h2><p>To use this script, we have to load the clean data that we saved in the previuos steps.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Load the earthquake data and add a column with ones since there was only one earthquake per row</span>
</span></span><span style=display:flex><span>df1 <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;data/earthquakes.csv&#39;</span>, header<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>del</span> df1[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>df1<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Date&#39;</span>]
</span></span><span style=display:flex><span>df1[<span style=color:#e6db74>&#39;earthquake&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>ones(len(df1))
</span></span><span style=display:flex><span>df1<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Load the movie data, the second column already shows us the sum of movie releases</span>
</span></span><span style=display:flex><span>df2 <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;data/filmrelease.csv&#39;</span>, header<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>del</span> df2[<span style=color:#e6db74>&#39;Unnamed: 0&#39;</span>]
</span></span><span style=display:flex><span>df2<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Date&#39;</span>, <span style=color:#e6db74>&#39;movie_release&#39;</span>]
</span></span><span style=display:flex><span>df2<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><p>As end result, we want to have a single DataFrame containing the data for both event series. Moreover, we want to have a continuous time series, including those days in which none of the two events took place (no earthquakes, and no movie releases). We do this by using the concatenate and resample functions of pandas.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Concatenate both DataFrames into one</span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat([df1, df2], ignore_index<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>set_index(pd<span style=color:#f92672>.</span>DatetimeIndex(df<span style=color:#f92672>.</span>Date))
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>sort_index()
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>resample(<span style=color:#e6db74>&#39;1d&#39;</span>)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>fillna(<span style=color:#ae81ff>0</span>) <span style=color:#75715e># to complete every day</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>)
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><h1 id=calculating-and-plotting-a-moving-average>Calculating and plotting a moving average<a hidden class=anchor aria-hidden=true href=#calculating-and-plotting-a-moving-average>#</a></h1><p>We could simply plot each event occurrence as a data point in a time series. However, this will likely yield a graph that is not very informative. Much easier to grasp is a moving average that tells us the average frequency of the events for a defined period of time in the past. We can create columns for these moving averages, which we can then easily plot.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Calculate moving average</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> [<span style=color:#ae81ff>7</span><span style=color:#f92672>*</span><span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>7</span><span style=color:#f92672>*</span><span style=color:#ae81ff>4</span><span style=color:#f92672>*</span><span style=color:#ae81ff>2</span>]:
</span></span><span style=display:flex><span>    mvav <span style=color:#f92672>=</span> i <span style=color:#75715e># moving average period, i.e. number of points to average</span>
</span></span><span style=display:flex><span>    dfi <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>convolve(df[<span style=color:#e6db74>&#39;earthquake&#39;</span>], 
</span></span><span style=display:flex><span>                      np<span style=color:#f92672>.</span>ones((mvav,))<span style=color:#f92672>*</span><span style=color:#ae81ff>7</span><span style=color:#f92672>/</span>mvav <span style=color:#75715e># factor for obtaining average</span>
</span></span><span style=display:flex><span>                      , mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;full&#39;</span>)
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#39;earthquake moving average </span><span style=color:#e6db74>%s</span><span style=color:#e6db74>w&#39;</span> <span style=color:#f92672>%</span> (int(i<span style=color:#f92672>/</span><span style=color:#ae81ff>7</span>))] <span style=color:#f92672>=</span> dfi[:<span style=color:#f92672>-</span>(i<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)]
</span></span><span style=display:flex><span>    dfj <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>convolve(df[<span style=color:#e6db74>&#39;movie_release&#39;</span>], 
</span></span><span style=display:flex><span>                      np<span style=color:#f92672>.</span>ones((mvav,))<span style=color:#f92672>*</span><span style=color:#ae81ff>7</span><span style=color:#f92672>/</span>mvav <span style=color:#75715e># factor for obtaining average</span>
</span></span><span style=display:flex><span>                      , mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;full&#39;</span>)
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#39;movie_release moving average </span><span style=color:#e6db74>%s</span><span style=color:#e6db74>w&#39;</span> <span style=color:#f92672>%</span> (int(i<span style=color:#f92672>/</span><span style=color:#ae81ff>7</span>))] <span style=color:#f92672>=</span> dfj[:<span style=color:#f92672>-</span>(i<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)]
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><pre><code>.dataframe thead th {
    text-align: left;
}

.dataframe tbody tr th {
    vertical-align: top;
}
</code></pre><p></p><p>The shorter the period that we choose for the moving average, the noisier our graphic will get. Let&rsquo;s settle with a moving average that reflects the frequency during the past 8 weeks. And <em>voil√†</em>! Now we can see how the frequency of earthquakes and movie releases changed over time.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Plot relevant columns from dataframe</span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>loc[:,[<span style=color:#e6db74>&#39;earthquake moving average 8w&#39;</span>, <span style=color:#e6db74>&#39;movie_release moving average 8w&#39;</span>]]<span style=color:#f92672>.</span>\
</span></span><span style=display:flex><span>plot(cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Set2&#39;</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>,<span style=color:#ae81ff>4</span>))<span style=color:#75715e># possible</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlim(df<span style=color:#f92672>.</span>index[<span style=color:#ae81ff>0</span>], df<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>max()<span style=color:#f92672>+</span><span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Moving average of events per week&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Frequency&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img alt=png loading=lazy src=/images/2017-02-06-event-tracker_files/2017-02-06-event-tracker_29_0.png></p><h1 id=descriptive-analysis-of-the-event-occurrence>Descriptive analysis of the event occurrence<a hidden class=anchor aria-hidden=true href=#descriptive-analysis-of-the-event-occurrence>#</a></h1><p>What other insights can we get from this data set? Two very dissimilar series of events, one natural, and one man-made, will surely have very different properties. Let&rsquo;s start with a simple question: on which days of the week do both events typically happen?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#%% DAY OF THE WEEK ANALYSIS</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create column for day of the week</span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Day&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>index<span style=color:#f92672>.</span>dayofweek
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Day&#39;</span>] <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>Day<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;category&#39;</span>)
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>Day<span style=color:#f92672>.</span>cat<span style=color:#f92672>.</span>categories <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Mon&#39;</span>,<span style=color:#e6db74>&#39;Tue&#39;</span>, <span style=color:#e6db74>&#39;Wed&#39;</span>, <span style=color:#e6db74>&#39;Thu&#39;</span>, <span style=color:#e6db74>&#39;Fri&#39;</span>, <span style=color:#e6db74>&#39;Sat&#39;</span>, <span style=color:#e6db74>&#39;Sun&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># create column for type</span>
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Type&#39;</span>] <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>where(df[<span style=color:#e6db74>&#39;earthquake&#39;</span>]<span style=color:#f92672>&gt;</span><span style=color:#ae81ff>0</span>, <span style=color:#e6db74>&#39;earthquake&#39;</span>, np<span style=color:#f92672>.</span>where(df[<span style=color:#e6db74>&#39;movie_release&#39;</span>]<span style=color:#f92672>&gt;</span><span style=color:#ae81ff>0</span>,\
</span></span><span style=display:flex><span> <span style=color:#e6db74>&#39;movie_release&#39;</span>, np<span style=color:#f92672>.</span>nan))
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Type&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;Type&#39;</span>]<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;category&#39;</span>)
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;Type&#39;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#39;Type&#39;</span>]<span style=color:#f92672>.</span>cat<span style=color:#f92672>.</span>remove_categories([<span style=color:#e6db74>&#39;nan&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># show count for each day</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#df[(df.Event1 == 1)&amp;(df.Day == &#39;Mon&#39;)].Day.count()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># plot count data per day of the week</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Event count per day of the week&#39;</span>)
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>countplot(data<span style=color:#f92672>=</span>df, x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Day&#39;</span>, hue<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Type&#39;</span>)
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>despine(left<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p><img alt=png loading=lazy src=/images/2017-02-06-event-tracker_files/2017-02-06-event-tracker_32_0.png></p><p>We can see that nature does not respect our weekends, as earthquakes seem to be flatly distributed by day of the week.</p><p>The movie releases, on the other hand, are most frequent on Friday, followed by Wednesday and a few on Sunday (it&rsquo;s almost as if movie release days were <em>chosen</em> by someone&mldr; /s). It seems that, if you&rsquo;re planning to release a new movie in the US, Friday is the way to go. People are usually happy to start the weekend with a leisurely activity, so that makes sense. As of why Saturdays and Sundays are almost not used as movie release days, even though on this days people are also usually free from work, it would be interesting to find out why. Another intriguing finding is the not high but remarkable number of releases on Wednesdays. Don&rsquo;t people work on Thursdays?</p><h2 id=analysis-of-frequency-per-week>Analysis of frequency per week<a hidden class=anchor aria-hidden=true href=#analysis-of-frequency-per-week>#</a></h2><p>The world is a big place (or is it a small world?) and earthquakes occur all the time, even though we might not always find out. On the other hand, I would expect that movie releases occur much more frequently. So let&rsquo;s take a look at the data by plotting histograms for both events side by side.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># joint histograms</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure()
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;earthquake moving average 8w&#39;</span>]<span style=color:#f92672>.</span>hist(alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.9</span>)
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#39;movie_release moving average 8w&#39;</span>]<span style=color:#f92672>.</span>hist(alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.9</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Histogram of event frequency per week&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># With seaborn</span>
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>distplot(df[<span style=color:#e6db74>&#39;earthquake moving average 8w&#39;</span>]), \
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>distplot(df[<span style=color:#e6db74>&#39;movie_release moving average 8w&#39;</span>])
</span></span></code></pre></div><p><img alt=png loading=lazy src=/images/2017-02-06-event-tracker_files/2017-02-06-event-tracker_36_0.png></p><pre><code>(&lt;matplotlib.axes._subplots.AxesSubplot at 0x11eb49198&gt;,
 &lt;matplotlib.axes._subplots.AxesSubplot at 0x11eb49198&gt;)
</code></pre><p><img alt=png loading=lazy src=/images/2017-02-06-event-tracker_files/2017-02-06-event-tracker_36_2.png></p><p>Luckily, movie releases are much more frequent per week as earthquakes. On most weeks, there are between two and three movie releases, compared to 0.5 to 1.5 earthquakes.</p><h1 id=final-remarks>Final remarks<a hidden class=anchor aria-hidden=true href=#final-remarks>#</a></h1><p>In this post, we gathered information on the occurrence of two events: earthquakes around the world, and movie releases in the US. By plotting their moving averages we could better compare when they occurred and gained some interesting insights about how they compare. All thanks to Python!</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.arcosdiaz.com/blog/tags/time-series/>Time Series</a></li><li><a href=https://www.arcosdiaz.com/blog/tags/visualization/>Visualization</a></li></ul><nav class=paginav><a class=prev href=https://www.arcosdiaz.com/blog/posts/2017-02-06-medicare-drug-cost/><span class=title>¬´ Prev</span><br><span>Exploratory analysis of Medicare drug cost data 2011-2015</span>
</a><a class=next href=https://www.arcosdiaz.com/blog/posts/2016-10-15-product-revenue-forecast/><span class=title>Next ¬ª</span><br><span>Simulating the revenue of a product with Monte-Carlo random walks</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://www.arcosdiaz.com/blog/>Dario Arcos-D√≠az, PhD</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>